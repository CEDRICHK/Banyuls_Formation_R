<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Analyse de données sous R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Cédric Hassen-Khodja" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Analyse de données sous R
]
.subtitle[
## Jour 3
]
.author[
### Cédric Hassen-Khodja
]
.institute[
### BioCampus Montpellier, MRI
]
.date[
### <p><img src="logo_MRI.png" style="width:3in" /></p>
]

---




<div>
<style type="text/css">.xaringan-extra-logo {
width: 110px;
height: 128px;
z-index: 0;
background-image: url(logo_cnrs.png);
background-size: contain;
background-repeat: no-repeat;
position: absolute;
top:1em;right:1em;
}
</style>
<script>(function () {
  let tries = 0
  function addLogo () {
    if (typeof slideshow === 'undefined') {
      tries += 1
      if (tries < 10) {
        setTimeout(addLogo, 100)
      }
    } else {
      document.querySelectorAll('.remark-slide-content:not(.title-slide):not(.inverse):not(.hide_logo)')
        .forEach(function (slide) {
          const logo = document.createElement('div')
          logo.classList = 'xaringan-extra-logo'
          logo.href = null
          slide.appendChild(logo)
        })
    }
  }
  document.addEventListener('DOMContentLoaded', addLogo)
})()</script>
</div>

# Objectifs d'apprentissage

1. Apprendre les tests paramétriques pour analyses univariées.

2. Apprendre les tests non paramétriques pour analyses univariées.

3. Apprendre comment identifier un modèle dont les conditions d'application ne sont pas rencontrées et comment régler le problème.

4. Identifier les situations où il est approprié d'utiliser des modèles linéaires généralisés.

5. Tester les hypothèses des modèles linéaires généralisés.

6. Implémenter et executer des modèles linéaires généralisés avec des données binaires, de proportion, et d'abondance.

7. Valider, interpreter et visualiser les résultats de modèles linéaires généralisés.

---

# Régression linéaire avec R

## Cas d'étude

&gt; Nous souhaitons analyser la relation entre le maximum journalier de la concentration en ozone (en `\(\mu/m^3\)`) et la température. Nous disposons de 112 données relevées durant l'été 2001 à Rennes.

## Formulation du modèle

`$$Y = \beta_0 + \beta_1X + \epsilon$$`
où:

- La variable `\(\epsilon\)` = erreur de mesure.   
- Le coefficient `\(\beta_0\)` =  ordonnée à l'origine.   
- Le coefficient `\(\beta_1\)` =  pente.
---

## Formulation du modèle (suite)

`$$y_i = \beta_0 + \beta_1x_i + \epsilon_i$$`

`$$\min_{\beta_0,\beta1}\sum_{i=1}^{n}(y_i - \beta_0-\beta_1x_i)²$$`

`$$f(x) = \widehat{\beta_0} + \widehat{\beta_1}x$$`

`$$\widehat{y_i} = \widehat{\beta_0} + \widehat{\beta_1}x_i$$`

`$$\widehat{\epsilon_i} = y_i - \widehat{y_i}$$`

--

## Equation du modèle

$$\textrm{maxO3}_i = \beta_0 + \beta1 \times \textrm{T12}_i + \epsilon_i $$
---

## Estimation de la relation

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-1-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

## Hypothèses nulles

`\(\{^{H_0: R^2 = 0}_{H_0:\beta_0 = 0 \textrm{et} \beta_1=0}\)`

## Fonction R


```r
lm{stats}
ResuLM &lt;- lm(Variable_dependante ~ Facteur, tableau)
```

Formule du modèle sous `R` ?

--


```r
lm(maxO3 ~ T12, data = ozone)
```

---

# Régression linéaire avec R (suite)

**Etape 1:** Formuler et exécuter un modèle linéaire basé sur une hypothèse.

**Etape 2:** Vérifier les conditions d'application du modèle linéaire.

.pull-left[

*Conditions sont satisfaits ?*

**Etape 3:**

- Analyser les paramètres de régression.

- Tracer le modèle.

- Interpréter le modèle.
]

.pull-right[

*Conditions non satisfaites ?*

- Envisager l'utilisation d'un &lt;u&gt;Modèle linéaire généralisé&lt;/u&gt; (`GLM`).

- &lt;u&gt;Transformer les données&lt;/u&gt;: Retourner à l'Étape 1 avec des variables transformées.
]

---

# Régression linéaire avec R (suite)

## Étape 1. Formuler et exécuter un modèle linéaire


```r
reg.s &lt;- lm(maxO3 ~ T12, data = ozone)
```

- `reg.s`: Nouvel objet contenant le modèle linéaire.

- `maxO3 ~ T12`: Formule du modèle.

- `ozone`: objet contenant les variables.

---

## Étape 1. Formuler et exécuter un modèle linéaire


```r
reg.s &lt;- lm(maxO3 ~ T12, data = ozone)
reg.s
# 
# Call:
# lm(formula = maxO3 ~ T12, data = ozone)
# 
# Coefficients:
# (Intercept)          T12  
#     -27.420        5.469
```

.center[
*Comment les paramètres se comparent-ils à nos prédictions ?*
]

--

.center[
**Peut-on se fier aux estimations du modèle ?**
]

---

## Étape 2. Vérifier les conditions d'application avec les graphiques diagnostics



```r
par(mfrow=c(2,2))
plot(reg.s)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-6-1.png" width="396" style="display: block; margin: auto;" /&gt;

---

## Étape 2. Vérifier les conditions d'application avec les graphiques diagnostics

### Evaluation de l'hypothèse de normalité des résidus


.pull-left[
&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-7-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

.pull-right[

```r
shapiro.test(residuals(reg.s))
# 
# 	Shapiro-Wilk normality test
# 
# data:  residuals(reg.s)
# W = 0.99235, p-value = 0.792
```
]

---

## Étape 2. Vérifier les conditions d'application avec les graphiques diagnostics

### Evaluation de l'hypothèse d'homogénéité des résidus

.pull-left[
&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-9-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

.pull-right[

```r
car::ncvTest(reg.s)
# Non-constant Variance Score Test 
# Variance formula: ~ fitted.values 
# Chisquare = 3.550023, Df = 1, p = 0.059545
```
]

---

## Étape 2. Vérifier les conditions d'application avec les graphiques diagnostics

### Evaluation de points aberrants ou d'influenceurs dans un modèle de régression

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-11-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

## Étape 2. Vérifier les conditions d'application avec les graphiques diagnostics

Quand les conditions ne sont pas remplies :

1. Utiliser un **autre type de modèle** mieux adapté à l'hypothèse et aux données.

2. Essayer de **transformer** la réponse et / ou les prédicteurs

---

## Étape 3. Analyser les paramètres


```r
summary(reg.s)
# 
# Call:
# lm(formula = maxO3 ~ T12, data = ozone)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -38.079 -12.735   0.257  11.003  44.671 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(&gt;|t|)    
# (Intercept) -27.4196     9.0335  -3.035    0.003 ** 
# T12           5.4687     0.4125  13.258   &lt;2e-16 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 17.57 on 110 degrees of freedom
# Multiple R-squared:  0.6151,	Adjusted R-squared:  0.6116 
# F-statistic: 175.8 on 1 and 110 DF,  p-value: &lt; 2.2e-16
```

---

## Étape 3. Tracer le modèle


```r
plot(maxO3~T12, ozone)
abline(reg.s)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-13-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

## Étape 3. Interpréter le modèle

Le coefficient de régression `\(\beta_1\)` = 5.5 est significatif (p &lt; 2e-16; t = 13.26), ainsi que `\(\beta_0\)` = -27.4 (p = 0.003; t = -3.035). 61% de la variabilité de *maxO3* est expliquée par *T12*. La droite de régression est donc définie par l'équation:

$$ y = 5.5 \times x -27.4$$

---

# Régression linéaire avec R (suite)

&lt;img src="../images/defi.jpg" width="10%" style="display: block; margin: auto auto auto 0;" /&gt;

Dans cet exercice, nous allons nous concentrer sur la relation entre la température de l'eau (T_degC) et la salinité (Salnty). Les données figurent dans le fichier csv *bottle.csv*.

1. Importez le dataset dans R.

2. Formuler une hypothèse à partir de l'observation des données.

3. Ajuster un modèle pour évaluer cette hypothèse.

4. Vérifier les conditions d'application du modèle linéaire.

5. Interpréter et tracer le modèle.

<div class="countdown" id="timer_1896953d" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">08</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# Régression linéaire avec R (suite)

**Solution:**

1.


```r
# Importer le fichier csv dans R
dataset &lt;- read.csv("../../exercices/data/bottle.csv")
head(dataset)
#     T_degC   Salnty
# 1 13.87905 38.45331
# 2 14.53965 39.61878
# 3 18.11742 40.18853
# 4 15.14102 39.19476
# 5 15.25858 38.62595
# 6 18.43013 40.48401
```

---

# Régression linéaire avec R (suite)

**Solution:**

2.

.pull-left[

```r
# Exploration des variables
str(dataset); summary(dataset)
# 'data.frame':	100 obs. of  2 variables:
#  $ T_degC: num  13.9 14.5 18.1 15.1 15.3 ...
#  $ Salnty: num  38.5 39.6 40.2 39.2 38.6 ...
#      T_degC          Salnty     
#  Min.   :10.38   Min.   :37.07  
#  1st Qu.:14.01   1st Qu.:38.63  
#  Median :15.12   Median :39.42  
#  Mean   :15.18   Mean   :39.45  
#  3rd Qu.:16.38   3rd Qu.:40.18  
#  Max.   :19.37   Max.   :42.13
```
]

.pull-right[

```r
library(ggplot2)
ggplot(data = dataset, aes(x = T_degC, 
                           y = Salnty)) +
  geom_point()
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-17-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

---

# Régression linéaire avec R (suite)

**Solution:**

3.


```r
# Ajuster un modèle linéaire simple pour évaluer 
# la corrélation entre 
# T_degC et Salnty
model &lt;- lm(Salnty ~ T_degC, data = dataset)

# Afficher les résultats du modèle
summary(model)
```

---

# Régression linéaire avec R (suite)

**Solution:**

3.


```
# 
# Call:
# lm(formula = Salnty ~ T_degC, data = dataset)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -1.9073 -0.6835 -0.0875  0.5806  3.2904 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(&gt;|t|)    
# (Intercept) 35.29073    0.81704  43.193  &lt; 2e-16 ***
# T_degC       0.27376    0.05344   5.123 1.51e-06 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 0.9707 on 98 degrees of freedom
# Multiple R-squared:  0.2112,	Adjusted R-squared:  0.2032 
# F-statistic: 26.24 on 1 and 98 DF,  p-value: 1.508e-06
```

---

# Régression linéaire avec R (suite)

**Solution:**

4.

.pull-left[

```r
#Homoscédasticité
plot(model, which = 3)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-20-1.png" width="432" style="display: block; margin: auto;" /&gt;
]
.pull-right[

```r
#Homoscédasticité
car::ncvTest(model)
# Non-constant Variance Score Test 
# Variance formula: ~ fitted.values 
# Chisquare = 1.609083, Df = 1, p = 0.20462
```
]

---

# Régression linéaire avec R (suite)

**Solution:**

4.

.pull-left[

```r
#Normalité
plot(model,2)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-22-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

.pull-right[

```r
#Normalité
shapiro.test(residuals(model))
# 
# 	Shapiro-Wilk normality test
# 
# data:  residuals(model)
# W = 0.9748, p-value = 0.05204
```
]

---

# Régression linéaire avec R (suite)

**Solution:**

4.


```r
#Evaluation des points aberrants
plot(model,5)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-24-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

# Régression linéaire avec R (suite)

**Solution:**

5.

.pull-left[
&lt;u&gt;Equation du modèle:&lt;/u&gt; `\(Salnty = TdegC \times 0.27 + 35.29\)` 

&lt;u&gt;Interprétation:&lt;/u&gt;Le coefficient de régression `\(\beta_1\)` = 0.27 est significatif (p = 1.51e-6; t = 5.123), ainsi que `\(\beta_0\)` = 35.29 (p &lt; 2e-16; t = 43.193). 20% de la variabilité de *Salnty* est expliquée par *T_degC*.
]

.pull-right[

```r
plot(Salnty~T_degC, dataset)
abline(model)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-25-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

---

# Régression linéaire multiple

## Formulation du modèle

`$$y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + ... + \beta_px_{ip} + \epsilon_i,$$`

- Le paramètre `\(\beta_0\)` est **l'ordonnée à l'origine**.

- Le paramètre `\(\beta_1\)` quantifie **l'effet** de x sur y.

- Le résidu `\(\epsilon_i\)` représente la variation **non expliquée**.

- La **valeur prédite** de `\(y_i\)` se définit comme : `\(\hat{y}_i = \beta_0 + \beta_1x_{i1}+\beta_2x_{i2}+\beta_3x_{i3}+...+\beta_px_{ip}\)`.

---

# Régression linéaire multiple (suite)

## Conditions d'utilisation

- Les résidus de l'analyse doivent suivre une distribution normale.

- Les variables explicatives ne doivent pas être corrélés entre eux.

---

# Régression linéaire multiple (suite)

## Cas d'étude

&gt; Nous souhaitons analyser ici la relation entre le maximum journalier de la concentration en ozone (en `\(\mu/m^3\)`) et la température, la nébulosité, la projection du vent sur l'axe Est-Ouest à différentes heures de la journée et la concentration maximale de la veille du jour considéré.

---

# Régression linéaire multiple (suite)

## Importer les données


```r
ozone &lt;- read.table("../data/ozone.txt", header = TRUE)
ozone.m &lt;- ozone[,1:11]
summary(ozone.m)
#      maxO3              T9             T12             T15       
#  Min.   : 42.00   Min.   :11.30   Min.   :14.00   Min.   :14.90  
#  1st Qu.: 70.75   1st Qu.:16.20   1st Qu.:18.60   1st Qu.:19.27  
#  Median : 81.50   Median :17.80   Median :20.55   Median :22.05  
#  Mean   : 90.30   Mean   :18.36   Mean   :21.53   Mean   :22.63  
#  3rd Qu.:106.00   3rd Qu.:19.93   3rd Qu.:23.55   3rd Qu.:25.40  
#  Max.   :166.00   Max.   :27.00   Max.   :33.50   Max.   :35.50  
#       Ne9             Ne12            Ne15           Vx9         
#  Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :-7.8785  
#  1st Qu.:3.000   1st Qu.:4.000   1st Qu.:3.00   1st Qu.:-3.2765  
#  Median :6.000   Median :5.000   Median :5.00   Median :-0.8660  
#  Mean   :4.929   Mean   :5.018   Mean   :4.83   Mean   :-1.2143  
#  3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.: 0.6946  
#  Max.   :8.000   Max.   :8.000   Max.   :8.00   Max.   : 5.1962  
#       Vx12             Vx15            maxO3v      
#  Min.   :-7.878   Min.   :-9.000   Min.   : 42.00  
#  1st Qu.:-3.565   1st Qu.:-3.939   1st Qu.: 71.00  
#  Median :-1.879   Median :-1.550   Median : 82.50  
#  Mean   :-1.611   Mean   :-1.691   Mean   : 90.57  
#  3rd Qu.: 0.000   3rd Qu.: 0.000   3rd Qu.:106.00  
#  Max.   : 6.578   Max.   : 5.000   Max.   :166.00
```

---

# Régression linéaire multiple (suite)

## Représenter les variables

.pull-left[

```r
library(GGally)
ggpairs(ozone.m) 
```
]

.pull-right[
&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-28-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

---

## Evaluation de la linéarité entre la réponse et les variables explicatives numériques


.pull-left[

```r
library(car)
scatterplotMatrix(ozone.m) 
```
]

.pull-right[
&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-30-1.png" width="720" style="display: block; margin: auto;" /&gt;
]

---

## Estimer les paramètres


```r
reg.mul &lt;- lm(maxO3 ~ ., data = ozone.m)
summary(reg.mul)
```

---

## Estimer les paramètres (suite)


```
# 
# Call:
# lm(formula = maxO3 ~ ., data = ozone.m)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -53.566  -8.727  -0.403   7.599  39.458 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(&gt;|t|)    
# (Intercept) 12.24442   13.47190   0.909   0.3656    
# T9          -0.01901    1.12515  -0.017   0.9866    
# T12          2.22115    1.43294   1.550   0.1243    
# T15          0.55853    1.14464   0.488   0.6266    
# Ne9         -2.18909    0.93824  -2.333   0.0216 *  
# Ne12        -0.42102    1.36766  -0.308   0.7588    
# Ne15         0.18373    1.00279   0.183   0.8550    
# Vx9          0.94791    0.91228   1.039   0.3013    
# Vx12         0.03120    1.05523   0.030   0.9765    
# Vx15         0.41859    0.91568   0.457   0.6486    
# maxO3v       0.35198    0.06289   5.597 1.88e-07 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 14.36 on 101 degrees of freedom
# Multiple R-squared:  0.7638,	Adjusted R-squared:  0.7405 
# F-statistic: 32.67 on 10 and 101 DF,  p-value: &lt; 2.2e-16
```

---

## Quel modèle choisir ?

&lt;u&gt;Principe de parcimonie&lt;/u&gt;: expliquer le plus de variation avec le plus petit nombre de termes dans votre modèle -&gt; enlevez la variable qui est la moins significative.


```r
library(leaps)
choix &lt;- regsubsets(maxO3 ~ ., data = ozone.m, 
                    nbest = 1, nvmax = 11)
plot(choix, scale = "bic")
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-33-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

## Estimer les paramètres du modèle parcimonieux


```r
reg.fin &lt;- lm(maxO3~T12+Ne9+Vx9+maxO3v, data = ozone.m)
summary(reg.fin)
# 
# Call:
# lm(formula = maxO3 ~ T12 + Ne9 + Vx9 + maxO3v, data = ozone.m)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -52.396  -8.377  -1.086   7.951  40.933 
# 
# Coefficients:
#             Estimate Std. Error t value Pr(&gt;|t|)    
# (Intercept) 12.63131   11.00088   1.148 0.253443    
# T12          2.76409    0.47450   5.825 6.07e-08 ***
# Ne9         -2.51540    0.67585  -3.722 0.000317 ***
# Vx9          1.29286    0.60218   2.147 0.034055 *  
# maxO3v       0.35483    0.05789   6.130 1.50e-08 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 14 on 107 degrees of freedom
# Multiple R-squared:  0.7622,	Adjusted R-squared:  0.7533 
# F-statistic: 85.75 on 4 and 107 DF,  p-value: &lt; 2.2e-16
```

---

## Evaluer les conditions d'application du modèle parcimonieux


```r
library(performance)
check_model(reg.fin)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-35-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

## Evaluer les conditions d'application du modèle parcimonieux (suite)


```r
check_normality(reg.fin)
# Warning: Non-normality of residuals detected (p = 0.005).
check_heteroscedasticity(reg.fin)
# Warning: Heteroscedasticity (non-constant error variance) detected (p = 0.011).
```

---

## Transformer les données et Estimation des paramètres du modèle parcimonieux


```r
reg.fin2 &lt;- lm(log(maxO3)~T12+Ne9+Vx9+maxO3v, data = ozone.m)
summary(reg.fin2)
# 
# Call:
# lm(formula = log(maxO3) ~ T12 + Ne9 + Vx9 + maxO3v, data = ozone.m)
# 
# Residuals:
#      Min       1Q   Median       3Q      Max 
# -0.49613 -0.09266  0.00742  0.09471  0.45565 
# 
# Coefficients:
#               Estimate Std. Error t value Pr(&gt;|t|)    
# (Intercept)  3.7215532  0.1205635  30.868  &lt; 2e-16 ***
# T12          0.0260229  0.0052003   5.004 2.22e-06 ***
# Ne9         -0.0272182  0.0074069  -3.675 0.000374 ***
# Vx9          0.0160120  0.0065996   2.426 0.016929 *  
# maxO3v       0.0036546  0.0006344   5.761 8.14e-08 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 0.1534 on 107 degrees of freedom
# Multiple R-squared:  0.7359,	Adjusted R-squared:  0.726 
# F-statistic: 74.54 on 4 and 107 DF,  p-value: &lt; 2.2e-16
```

---

## Interprétation du modèle

L'analyse de régression linéaire multiple incluant les quatre régresseurs potentiels est significative (R² = 0.7359; p &lt; 2.2e-16; F = 74.54; `\(ddl_{numérateur} = 4\)`;
`\(ddl_{dénominateur} = 107\)`).La relation rend compte de 73,59% de la variance de la concentration en ozone. La concentration en ozone peut-être prédit par l'équation suivante:

`$$log(maxO3) = 0.026 \times T12 - 0.027 \times Ne9 + 0.016 \times Vx9 + 0.0036 \times maxO3v + 3.72$$`

---

# Régression linéaire multiple (suite)

&lt;img src="../images/defi.jpg" width="10%" style="display: block; margin: auto auto auto 0;" /&gt;

Dans cet exercice, nous allons étudier la relation entre une variable dépendante (price) et plusieurs variables explicatives (horsepower, curb-weight, engine-size et highway-mpg). Les données figurent dans le fichier csv *auto.csv*.

1. Importez le dataset dans R. Sélectionnez ensuite les variables d'intérêt pour la régression linéaire.

2. Formuler une hypothèse à partir de l'observation des données.

3. Ajuster un modèle pour évaluer cette hypothèse.

4. Vérifier les conditions d'application du modèle linéaire.

5. Interpréter le modèle.

6. Prédiction: Trouver le prix pour une voiture avec 150 horsepower, un curb weight de 3000, une engine size de 200 et une highway mpg de 30

<div class="countdown" id="timer_a7214d8b" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# Régression linéaire multiple (suite)

**Solution:**

1.


```r
# Import du dataset
auto &lt;- read.csv("../../exercices/data/auto.csv", header= TRUE, sep=",", check.names = FALSE)
# Sélection des variables d'intérêt
dataset &lt;- auto[,c("price", "horsepower", "curb-weight", "engine-size", "highway-mpg")]
dataset$horsepower &lt;- as.integer(dataset$horsepower)
dataset$price &lt;- as.integer(dataset$price)
dataset &lt;- na.omit(dataset)
```

---

# Régression linéaire multiple (suite)

2.


```r
library(ggplot2)
p1 &lt;- ggplot(data = dataset, aes(x = horsepower, 
                           y = price)) +
  geom_point()

p2 &lt;- ggplot(data = dataset, aes(x = `curb-weight`, 
                           y = price)) +
  geom_point()

p3 &lt;- ggplot(data = dataset, aes(x = `engine-size`, 
                           y = price)) +
  geom_point()

p4 &lt;- ggplot(data = dataset, aes(x = `highway-mpg`, 
                           y = price)) +
  geom_point()

gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2)
```

---

# Régression linéaire multiple (suite)

2.

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-41-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

# Régression linéaire multiple (suite)

3.


```r
# Ajustement du modèle
model &lt;- lm(price ~ horsepower + `curb-weight` + `engine-size` + `highway-mpg`, data=dataset)
```

---

# Régression linéaire multiple (suite)

4.


```r
performance::check_normality(model)
# Warning: Non-normality of residuals detected (p &lt; .001).
performance::check_heteroscedasticity(model)
# Warning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).

# Appliquer une transformation de la réponse
model &lt;- lm(1/price ~ horsepower + `curb-weight` + `engine-size` + `highway-mpg`, data=dataset)

performance::check_normality(model)
# OK: residuals appear as normally distributed (p = 0.220).
performance::check_heteroscedasticity(model)
# OK: Error variance appears to be homoscedastic (p = 0.327).
```

---

# Régression linéaire multiple (suite)

5.


```r
# Appliquer une transformation de la réponse
model &lt;- lm(1/price ~ horsepower + `curb-weight` + `engine-size` + `highway-mpg`, data=dataset)
summary(model)
# 
# Call:
# lm(formula = 1/price ~ horsepower + `curb-weight` + `engine-size` + 
#     `highway-mpg`, data = dataset)
# 
# Residuals:
#        Min         1Q     Median         3Q        Max 
# -5.298e-05 -1.090e-05  1.077e-06  9.643e-06  5.828e-05 
# 
# Coefficients:
#                 Estimate Std. Error t value Pr(&gt;|t|)    
# (Intercept)    2.450e-04  2.249e-05  10.894  &lt; 2e-16 ***
# horsepower    -4.060e-07  7.545e-08  -5.381 2.12e-07 ***
# `curb-weight` -5.984e-08  5.737e-09 -10.430  &lt; 2e-16 ***
# `engine-size`  2.396e-07  7.210e-08   3.324  0.00106 ** 
# `highway-mpg`  5.423e-07  3.800e-07   1.427  0.15513    
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# Residual standard error: 1.796e-05 on 194 degrees of freedom
# Multiple R-squared:  0.8239,	Adjusted R-squared:  0.8203 
# F-statistic: 226.9 on 4 and 194 DF,  p-value: &lt; 2.2e-16
```

---

# Régression linéaire multiple (suite)

5.

&lt;u&gt;Interprétation:&lt;/u&gt;Les résultats montrent que toutes les variables explicatives ont des coefficients significatifs sauf la variable highway-mpg qui n'est pas significative avec une valeur de p de 0,15513.

- Le coefficient de détermination (R²) de 0,8239 indique que le modèle explique 82,39% de la variabilité de la variable réponse. Le F-statistic de 226,9 avec un p-value très faible indique que le modèle est globalement significatif.

---

# Régression linéaire multiple (suite)

6.


```r
# Prédiction du prix original
horsepower &lt;- 150
curb_weight &lt;- 3000
engine_size &lt;- 200
highway_mpg &lt;- 30

# Utilisation de l'équation pour prédire 1/price
prediction &lt;- 2.450e-04 - 4.060e-07 * horsepower - 5.984e-08 * curb_weight + 2.396e-07 * engine_size + 5.423e-07 * highway_mpg

# Inverse de la fonction inverse pour obtenir le prix original
prix &lt;- 1 / prediction

prix
# [1] 14541.44
```

---

# Test de Student

## Utilisation

Comparer les moyennes de deux groupes indépendants.

## Conditions d'application

- **Normalité**: les échantillons (n &lt; 30) issus de populations suivent une distribution normale.

- **Homogénéité de variances**: la variance des groupes sont homogènes.

---

# Test de Student

## Fonction R


```r
# t.test{stats}

# Test bilatéral:
t.test(groupe1, groupe2)

# Tests unilatéraux:
t.test(groupe1, groupe2, alternative = "greater")
t.test(groupe1, groupe2, alternative = "less`")
```

Le test `t` est un modèle linéaire et un cas spécifique de l'ANOVA.

Vous pouvez donc aussi utiliser la fonction `lm()`.

```r
lm.t &lt;- lm(Y ~ X2, data = data)
anova(lm.t)
```

---

# Test de Student (suite)

## Cas d'étude

&gt; Nous allons comparer les poids de poulpes mâles et femelles au stade adulte. Nous disposons pour cela des données de poids pour 13 poulpes femelles (population notée 1) et 15 poulpes mâles (population notée 2) pêchés au large des côtes mauritaniennes.

### Importer les données


```r
data &lt;- read.table("../data/poulpe.csv", header = T, sep = ",")
summary(data)
#      Poids          Sexe          
#  Min.   : 300   Length:28         
#  1st Qu.:1480   Class :character  
#  Median :1800   Mode  :character  
#  Mean   :2099                     
#  3rd Qu.:2750                     
#  Max.   :5400
```

---

### Visualiser les données


```r
boxplot(Poids ~ Sexe,
        data = data, xlab = "Sexe", ylab = "Poids")
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-49-1.png" width="468" style="display: block; margin: auto;" /&gt;

---

## Vérifier les conditions d'application

### Tester la normalité des données


```r
select.males &lt;- data$Poids[data$Sexe == "Male"]
select.femelles &lt;- data$Poids[data$Sexe == "Femelle"]

shapiro.test(select.males)
# 
# 	Shapiro-Wilk normality test
# 
# data:  select.males
# W = 0.93501, p-value = 0.3238
shapiro.test(select.femelles)
# 
# 	Shapiro-Wilk normality test
# 
# data:  select.femelles
# W = 0.97109, p-value = 0.9069
```

---

## Vérifier les conditions d'application

### Tester l'égalité des variances

- Un test d'hétérogéneité de variance précédé l'utilisation du t-test.

- La **correction de Welch** rend cette étape inutile.

---

## Réalisation du test

### Tester l'égalité des moyennes


```r
t.test(Poids~Sexe, var.equal = FALSE, data = data)
# 
# 	Welch Two Sample t-test
# 
# data:  Poids by Sexe
# t = -3.7496, df = 22.021, p-value = 0.001107
# alternative hypothesis: true difference in means between group Femelle and group Male is not equal to 0
# 95 percent confidence interval:
#  -2010.624  -578.607
# sample estimates:
# mean in group Femelle    mean in group Male 
#              1405.385              2700.000
```

---

## Interprétation

Les résultats montrent que les moyennes observées dans l'échantillon (1405g pour les femelles et 2700 pour les mâles) sont suffisamment différentes et significative (p = 0.001107; t = 3.74; dll = 22.021; test t de Student unilatéral pour chantillons indépendants avec correction de Welch).   

--


```r
t.test(Poids~Sexe, var.equal = FALSE, data = data, alternative = "greater")
# 
# 	Welch Two Sample t-test
# 
# data:  Poids by Sexe
# t = -3.7496, df = 22.021, p-value = 0.9994
# alternative hypothesis: true difference in means between group Femelle and group Male is greater than 0
# 95 percent confidence interval:
#  -1887.471       Inf
# sample estimates:
# mean in group Femelle    mean in group Male 
#              1405.385              2700.000
```

On accepte `\(H_0\)` selon laquelle les femelles sont plus légères que les mâles.

---

# Test de Student (suite)

## Non respect des conditions

- **Correction de Welch**: par défaut dans R.

- **Test de Mann-Whitney**: équivalent non paramétrique.

- **Test de t apparié**: lorsque les deux groupes ne sont pas indépendants (par exemple, des mesures sur la même personne récoltées lors de 2 années différentes).

---

# Test de Student (suite)

&lt;img src="../images/defi.jpg" width="10%" style="display: block; margin: auto auto auto 0;" /&gt;

&lt;u&gt;But de l'exercice&lt;/u&gt;: Déterminer s'il y a une différence significative entre les scores de mathématiques des étudiants en fonction de leur sexe.

&lt;u&gt;Dataset&lt;/u&gt;:  Le dataset contient les scores de mathématiques de 100 étudiants (50 femmes et 50 hommes). Les données figurent dans le fichier csv *math.csv*. 

1. Importez le dataset dans R et examinez les données.

2. Effectuez un test de normalité pour déterminer si les scores de mathématiques suivent une distribution normale pour les deux groupes (hommes et femmes).

3. Effectuez un test de Student pour déterminer s'il y a une différence significative entre les scores de mathématiques des hommes et des femmes.

4. Interprétez les résultats et concluez si les scores de mathématiques diffèrent significativement en fonction du sexe.

<div class="countdown" id="timer_ef4e75f6" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# Test de Student (suite)

**Solution:**

1.


```r
# Importer les données
data &lt;- read.csv("../../presentation/data/math.csv")

# Afficher les premières lignes du dataset
head(data)
#   math_score gender
# 1         62      F
# 2         71      M
# 3         58      F
# 4         69      M
# 5         77      M
# 6         83      M
```
---

# Test de Student (suite)

1.

.pull-left[

```r
# Résumé statistique
summary(data)
#    math_score       gender         
#  Min.   :56.00   Length:114        
#  1st Qu.:67.00   Class :character  
#  Median :72.00   Mode  :character  
#  Mean   :72.39                     
#  3rd Qu.:78.00                     
#  Max.   :88.00
```
]

.pull-right[

```r
# Boxplot des scores de mathématiques en fonction du sexe
boxplot(math_score ~ gender, data = data)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-56-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

---

# Test de Student (suite)

2.


```r
# Test de normalité pour les scores des femmes
shapiro.test(data$math_score[data$gender == "F"])
# 
# 	Shapiro-Wilk normality test
# 
# data:  data$math_score[data$gender == "F"]
# W = 0.9775, p-value = 0.413

# Test de normalité pour les scores des hommes
shapiro.test(data$math_score[data$gender == "M"])
# 
# 	Shapiro-Wilk normality test
# 
# data:  data$math_score[data$gender == "M"]
# W = 0.98672, p-value = 0.7502
```

---

# Test de Student (suite)

3.


```r
t.test(math_score ~ data$gender, data = data)
# 
# 	Welch Two Sample t-test
# 
# data:  math_score by data$gender
# t = -3.2617, df = 106.25, p-value = 0.001489
# alternative hypothesis: true difference in means between group F and group M is not equal to 0
# 95 percent confidence interval:
#  -6.912219 -1.685987
# sample estimates:
# mean in group F mean in group M 
#        70.09434        74.39344
```

---

# Test de Student (suite)

4.

&lt;u&gt;Interprétation:&lt;/u&gt;Le modèle Welch Two Sample t-test permet de déterminer s'il y a une différence significative entre les scores de mathématiques des hommes et des femmes. Dans ce cas, la statistique de test t a une valeur de -3.2617 avec un degré de liberté (df) de 106.25 et une p-value de 0.001489.

- On peut donc conclure qu'il y a une différence significative entre les scores de mathématiques des deux groupes.

---

# ANOVA à un facteur

## Utilisation

- Comparer les moyennes de plus de deux groupes.

## Conditions d'utilisation

- **Normalité des résidus**: les échantillons doivent être issus de populations suivant une distribution normale. 

- **Homogénéité de variances**: sinon appliqué une correction de Welch.

## Hypothèse nulle

`\(H_0: F = 1\)`

---

# ANOVA à un facteur(suite)

## Fonction R

&gt; aov{stats}

- ANOVA avec correction de Welch:

&gt; oneway.test{stats}


```r
# Effectue l'analyse et stocke les résultats
resAOV &lt;- aov(Variable_dependante ~ Facteur)
# Permet de lire les résultats
summary(resAOV)
# ANOVA avec correction de Welch
oneway.test(Variable_dependante ~ Facteur)
```

---

# ANOVA à un facteur(suite)

## Test de comparaison par paires

- Lorsque l'ANOVA détecte une différence significative entre les groupes, l'analyse n'indique pas quel(s) groupe(s) diffère(nt) de(s) l'autre(s)

&gt; TukeyHSD{stats}   
&gt; Tukey{resAOV}

- si variance hétérogène:

&gt; rstatix::games_howell_test()

- si témoin:

&gt; DescTools::DunnettTest()

---

# ANOVA à un facteur(suite)

## Cas d'étude

&gt; Nous reprenons le jeu de données ozone. Nous souhaitons analyser ici la relation entre le maximum journalier de la concentration en ozone (en `\(\mu/m^3\)`) avec la précipitation classée en deux modalités : Sec et Pluie

### Importer les données


```r
ozone &lt;- read.table("../data/ozone.txt", header = TRUE)
summary(ozone[,c("maxO3", "pluie")])
#      maxO3           pluie          
#  Min.   : 42.00   Length:112        
#  1st Qu.: 70.75   Class :character  
#  Median : 81.50   Mode  :character  
#  Mean   : 90.30                     
#  3rd Qu.:106.00                     
#  Max.   :166.00
```

---

### Visualiser les données


```r
boxplot(maxO3~pluie, data = ozone)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-61-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

### Réalisation du test



```r
anova.simple &lt;- aov(maxO3~pluie, data = ozone)
summary(anova.simple)
#              Df Sum Sq Mean Sq F value   Pr(&gt;F)    
# pluie         1  19954   19954   32.17 1.16e-07 ***
# Residuals   110  68238     620                     
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---

## Vérifier les conditions d'application du test

### Tester la normalité des résidus


```r
shapiro.test(resid(anova.simple))
# 
# 	Shapiro-Wilk normality test
# 
# data:  resid(anova.simple)
# W = 0.92392, p-value = 8.027e-06
```

---

## Vérifier les conditions d'application du test (suite)

### Tester l'égalité de variance entre les groupes


```r
bartlett.test(maxO3~pluie, data = ozone)
# 
# 	Bartlett test of homogeneity of variances
# 
# data:  maxO3 by pluie
# Bartlett's K-squared = 12.027, df = 1, p-value = 0.0005242
```

---

## Non respect des conditions

- **Transformer vos données** : pourrait égaliser les variances et normaliser les résidus, et peut convertir un effet multiplicatif en un effet additif.

  - ré-exécuter votre modèle avec la variable transformée et vérifier à nouveau les hypothèses.

- **Test de Kruskal-Wallis**: équivalent non paramétrique de l'ANOVA si vous ne pouvez pas (ou ne voulez pas) transformer les données.

---

## Test de Kruskal-Wallis

### Fonction R

&gt; kruskal.test{stats}   
&gt; kruskal.test{Variable_dependante ~ Facteur}

---

### Réalisation du test


```r
kw &lt;- kruskal.test(maxO3~pluie, data = ozone)
kw
# 
# 	Kruskal-Wallis rank sum test
# 
# data:  maxO3 by pluie
# Kruskal-Wallis chi-squared = 31.374, df = 1, p-value = 2.128e-08
```

### Interprétation

Le test de Kruskal-Wallis montre un effet significatif du facteur `pluie` (p=2.128e-08; KS = 31.374; ddl = 1).

---

# ANOVA à deux facteurs

## Utilisation

- Déterminer si deux facteurs interagissent statistiquement.

- Les facteurs ont-ils un effet sur la variable quantitative dépendante ?

## Conditions d'utilisation

Voir ANOVA à un facteur.

---

## Fonction R

- Plan équilibré:
&gt; aov{stats}   
&gt;resAOV &lt;- aov(Variable_dependante ~ Facteur 1 * Facteur 2)   
&gt;summary(resAOV)

- Plan déséquilibré:
&gt; Anova{car}   
resType3 &lt;- Anova((VarDep ~ Facteur1 * Facteur2, data = Donnees,
contrast = list(Facteur1 = "contr.sum", Facteur2 = "contr.sum")), type = "III")

---

# ANOVA à deux facteurs (suite)

## Cas d'étude

&gt; Nous souhaitons analyser ici la relation entre le maximum de journalier de la concentration en ozone (en `\(\mu/m^3\)`) avec la précipitation classée en deux modalités : Sec et Pluie et avec la direction du vent classée en secteur: Nord, Sud, Est, Ouest.

### Importer les données


```r
ozone &lt;- read.table("../data/ozone.txt", header = TRUE)
summary(ozone[,c("maxO3", "vent", "pluie")])
#      maxO3            vent              pluie          
#  Min.   : 42.00   Length:112         Length:112        
#  1st Qu.: 70.75   Class :character   Class :character  
#  Median : 81.50   Mode  :character   Mode  :character  
#  Mean   : 90.30                                        
#  3rd Qu.:106.00                                        
#  Max.   :166.00
```

---

### Visualiser les données


```r
boxplot(maxO3~vent*pluie, data = ozone)
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-67-1.png" width="720" style="display: block; margin: auto;" /&gt;

---

### Prévisualisation des interactions


```r
par(mfrow=c(1,2))
interaction.plot(ozone$vent, ozone$pluie, ozone$maxO3, 
                 type = "b", pch = 1:3, ylab = "ozone", 
                 xlab = "vent", bty = "n")
interaction.plot(ozone$pluie, ozone$vent, ozone$maxO3, 
                 type = "b", pch = 1:3, ylab = "ozone", 
                 xlab = "pluie", bty = "n")
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-68-1.png" width="576" style="display: block; margin: auto;" /&gt;

---

### Choix du test


```r
table(ozone$pluie, ozone$vent)
#        
#         Est Nord Ouest Sud
#   Pluie   2   10    26   5
#   Sec     8   21    24  16
```

---

### Réalisation du test



```r
library(car)
Res &lt;- lm(maxO3~pluie*vent, data = ozone)
Anova(Res, contrast = list(pluie = "contr.sum", vent = "contr.sum"),type = "III")
# Anova Table (Type III tests)
# 
# Response: maxO3
#             Sum Sq  Df F value    Pr(&gt;F)    
# (Intercept)   9940   1 16.2960 0.0001038 ***
# pluie         3080   1  5.0492 0.0267490 *  
# vent          1912   3  1.0445 0.3761481    
# pluie:vent    1006   3  0.5500 0.6492869    
# Residuals    63440 104                      
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

### Interprétation

La probabilité critique (0.65) est supérieure à 5% donc on ne peut pas rejeter `\(H_0\)` et on conclut à la non significativité de l'interaction. Nous estimons donc le modèle sans interaction

---

### Réalisation du test (modèle sans interaction)


```r
library(car)
Res &lt;- lm(maxO3~pluie+vent, data = ozone)
Anova(Res, contrast = list(pluie = "contr.sum", vent = "contr.sum"),type = "III")
# Anova Table (Type III tests)
# 
# Response: maxO3
#             Sum Sq  Df F value    Pr(&gt;F)    
# (Intercept)  57530   1 95.5173 &lt; 2.2e-16 ***
# pluie        16159   1 26.8295 1.052e-06 ***
# vent          3791   3  2.0982    0.1048    
# Residuals    64446 107                      
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

### Interprétation

La probabilité critique associée à l'effet `vent` (0.10) est supérieure à 5% donc on conclut à la non-significativité de ce facteur: il n'y a pas d'effet de la direction du vent sur le maximum d'ozone journalier. Avant de conclure sur l'effet du facteur `pluie`, nous devons ajuster le modèle d'ANOVA à un facteur -&gt; Voir chapitre correspondant.

---

# ANOVA pour plans mixtes

## Utilisation

Etude des effets et de l'interaction entre au moins un facteur **fixe** et au moins un facteur  **aléatoire**.

## Conditions d'utilisation

Voir ANOVA à un facteur.

## Stratégie

1. définir un modèle dit *nul*.

2. définir un modèle mixte avec effet aléatoire sans interaction.

3. définir un modèle mixte considérant une interaction entre l'effet fixe et l'effet aléatoire.

---

# ANOVA pour plans mixtes (suite)

## Fonction R

&gt; lmer{lmeTest} (lmerTest nécessite lme4)

- Modèle sans interaction

&gt;ResMixNoInt &lt;- lmer(VarDep ~ FactFix + (1|FactAlea), data = Donnee)

- Modèle avec interaction

&gt;ResMixInt &lt;- lmer(VarDep ~ FactFix + (1+FactFix|FactAlea), data = Donnee)

---

# ANOVA pour plans mixtes (suite)

## Cas d'étude

&gt; On cherche à évaluer l'effet de la température sur la consommation d'oxygène des crustacés d'une région.

### Importer les données


```r
crustace &lt;- read.table("../data/Crustace.txt", 
                       header = TRUE)
crustace$Temper &lt;- as.factor(crustace$Temper)
summary(crustace)
#  Temper      EspS                Oxyg       
#  10:80   Length:240         Min.   : 0.810  
#  20:80   Class :character   1st Qu.: 3.667  
#  30:80   Mode  :character   Median : 4.805  
#                             Mean   : 4.943  
#                             3rd Qu.: 6.185  
#                             Max.   :11.030
```

---

### Visualiser les données


```r
par(mfrow=c(1,2))
boxplot(Oxyg~Temper, data = crustace)
abline(h = median(crustace$Oxyg))
boxplot(Oxyg~EspS, data = crustace)
abline(h = median(crustace$Oxyg))
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-73-1.png" width="720" style="display: block; margin: auto;" /&gt;

---

### Définition des modèles à comparer


```r
library(lmerTest)

ResIntNULL &lt;- lm(Oxyg ~ Temper, data = crustace)
ResNoInt &lt;- lmer(Oxyg ~ Temper + (1|EspS), data = crustace)
ResInt &lt;- lmer(Oxyg ~ Temper + (1+Temper|EspS), data = crustace)
```

---

### Choix du modèle


```r
anova(ResInt, ResNoInt, ResIntNULL)
# Data: crustace
# Models:
# ResIntNULL: Oxyg ~ Temper
# ResNoInt: Oxyg ~ Temper + (1 | EspS)
# ResInt: Oxyg ~ Temper + (1 + Temper | EspS)
#            npar    AIC    BIC  logLik deviance   Chisq Df Pr(&gt;Chisq)    
# ResIntNULL    4 967.61 981.54 -479.81   959.61                          
# ResNoInt      5 912.57 929.97 -451.29   902.57 57.0409  1  4.268e-14 ***
# ResInt       10 913.49 948.30 -446.75   893.49  9.0776  5      0.106    
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

&lt;u&gt;Interprétation:&lt;/u&gt; L'effet aléatoire *espèce* améliore significativement le modèle (p=4.268e-14), en revanche l'interaction ne semble pas améliorer le modèle (p = 0.106).

---

### Analyse de variance de type 2 sur le meilleur modèle


```r
anova(ResNoInt, type = 2)
# Type II Analysis of Variance Table with Satterthwaite's method
#        Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    
# Temper 119.68   59.84     2   230  25.637 8.886e-11 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

&lt;u&gt;Interprétation:&lt;/u&gt; L'effet fixe *températue* est significatif, il existe bien un effet de la température sur la consommation en oxygène des crustacés.

---

### Représentation graphique du modèle


```r
library(effects)

# Fit the mixed effects model
model &lt;- lmer(Oxyg ~ Temper + (1|EspS), data = crustace)

# Calculate the marginal effects
plot(allEffects(model))
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-77-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

### Représentation graphique du modèle (suite)


```r
library(ggplot2)

# Obtenir les prédictions pour chaque espèce
crustace$predicted &lt;- fitted(ResNoInt)

# Tracer un graphique en ligne pour chaque espèce
ggplot(crustace, aes(x = Temper, y = predicted, group = as.factor(EspS), color = as.factor(EspS))) +
  geom_line() +
  xlab("Température") +
  ylab("Oxygène prédit") +
  ggtitle("Effet de la température sur l'oxygène par espèce")
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-78-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

# ANOVA pour plans mixtes (suite)

&lt;img src="../images/defi.jpg" width="10%" style="display: block; margin: auto auto auto 0;" /&gt;

&lt;u&gt;Objectif&lt;/u&gt;: Réaliser une analyse de variance (ANOVA) mixte en choisissant le meilleur modèle à partir du jeu de données *sleepstudy*, de la librairie lme4, qui contient les temps de réaction de sujets à un test de sommeil en fonction de deux facteurs: la durée du sommeil et le sujet lui-même.

&lt;u&gt;Instructions&lt;/u&gt;:

1. Importez le jeu de données.
2. Explorer les données.
3. Créer les différents modèles.
4. Comparer les modèles.
5. Analyser les effets fixes du modèle.
6. Interprétation.
7. Représentation graphique.

<div class="countdown" id="timer_04e05e89" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# ANOVA pour plans mixtes (suite)

**Solution:**
1.


```r
data("sleepstudy")
str(sleepstudy)
# 'data.frame':	180 obs. of  3 variables:
#  $ Reaction: num  250 259 251 321 357 ...
#  $ Days    : num  0 1 2 3 4 5 6 7 8 9 ...
#  $ Subject : Factor w/ 18 levels "308","309","310",..: 1 1 1 1 1 1 1 1 1 1 ...
```

---

# ANOVA pour plans mixtes (suite)

2.

.pull-left[

```r
summary(sleepstudy)
#     Reaction          Days        Subject   
#  Min.   :194.3   Min.   :0.0   308    : 10  
#  1st Qu.:255.4   1st Qu.:2.0   309    : 10  
#  Median :288.7   Median :4.5   310    : 10  
#  Mean   :298.5   Mean   :4.5   330    : 10  
#  3rd Qu.:336.8   3rd Qu.:7.0   331    : 10  
#  Max.   :466.4   Max.   :9.0   332    : 10  
#                                (Other):120
```
]

.pull-right[

```r
plot(sleepstudy$Days, sleepstudy$Reaction, 
     xlab = "Days", ylab = "Reaction", main = "Sleep Study")
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-82-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

---

# ANOVA pour plans mixtes (suite)

3.


```r
model1 &lt;- lm(Reaction ~ Days, data = sleepstudy)
model2 &lt;- lmer(Reaction ~ Days + (1|Subject), data = sleepstudy)
model3 &lt;- lmer(Reaction ~ Days + (1+Days|Subject), data = sleepstudy)
```

---

# ANOVA pour plans mixtes (suite)

4.


```r
anova(model2, model1, model3)
# Data: sleepstudy
# Models:
# model1: Reaction ~ Days
# model2: Reaction ~ Days + (1 | Subject)
# model3: Reaction ~ Days + (1 + Days | Subject)
#        npar    AIC    BIC  logLik deviance   Chisq Df Pr(&gt;Chisq)    
# model1    3 1906.3 1915.9 -950.15   1900.3                          
# model2    4 1802.1 1814.8 -897.04   1794.1 106.214  1  &lt; 2.2e-16 ***
# model3    6 1763.9 1783.1 -875.97   1751.9  42.139  2  7.072e-10 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

&lt;u&gt;Interprétation:&lt;/u&gt; Mettre l'effet *Sujet* en aléatoire améliore significativement le modèle (p &lt; 2.2e-16), mais moindre que l'interaction.

---

# ANOVA pour plans mixtes (suite)

6.


```r
anova(model2, type = 2)
# Type II Analysis of Variance Table with Satterthwaite's method
#      Sum Sq Mean Sq NumDF DenDF F value    Pr(&gt;F)    
# Days 162703  162703     1   161   169.4 &lt; 2.2e-16 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

&lt;u&gt;Interprétation:&lt;/u&gt; Nous constatons que l'effet fixe *Jour* est significatif, il existe bien un effet de privation de sommeil sur le temps de réaction des sujets.

---

# ANOVA pour plans mixtes (suite)

7.


```r
library(ggplot2)
# Obtenir les prédictions pour chaque sujet
sleepstudy$predicted &lt;- fitted(model2)
# Tracer un graphique en ligne pour chaque espèce
ggplot(sleepstudy, aes(x = Days, y = predicted, group = as.factor(Subject), color = as.factor(Subject))) +
  geom_line() +
  xlab("Days") +
  ylab("Temps de réaction prédit") +
  ggtitle("Effet de privation de sommeil sur différents sujets")
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-86-1.png" width="432" style="display: block; margin: auto;" /&gt;

---

# Les modèles linéaires généralisés (GLM)

## Utilisation et principe de fonctionnement

- Généralisation de la régression linéaire.
- Alternative à l'ANOVA lorsque la variable dépendante ne suit pas une distribution normale.
  - Observations comme variables quantitatives discrètes.
  - Observations comme variables qualitatives binaires.
- Fait intervenir une fonction de lien.
  - Adapter une famille de loi de distribution de la variable dépendante.
- Pour les données de comptage:
  - Loi de Poisson ou loi binomiale négative.
- Pour les données binaires:
  - Loi binomiale.
- Le test de significativité fait intervenir la loi de `\(\chi^2\)`.

---

# Les modèles linéaires généralisés (GLM)

## Distribution de Poisson

- **Poisson** est une distribution discrète avec un seul paramètre, `\(\lambda\)` (lambda), qui détermine la moyenne et la variance de la distribution:

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-87-1.png" width="1080" style="display: block; margin: auto;" /&gt;

---

# Les modèles linéaires généralisés (GLM)

## Distribution de Bernouilli

- N'inclut que deux issues possibles dans son ensemble: succès (`1`) ou échec (`0`)
- N'a qu'un paramètre, `\(p\)`, la probabilité de succès

&lt;br&gt;
&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-88-1.png" width="1080" style="display: block; margin: auto;" /&gt;

---

# Les modèles linéaires généralisés (GLM)

## Distribution binomiale

Lorsqu'il y a plusieurs épreuves (chacune avec un succès/échec), la loi de Bernoulli devient la loi binomiale

- Inclut le paramètre additionel `\(n\)`, le nombre d'épreuves
- Prédit la probabilité d'observer une certaine proportion de succès, `\(p\)`, sur le nombre total d'épreuves, `\(n\)`

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-89-1.png" width="1080" style="display: block; margin: auto;" /&gt;

---

# Les modèles linéaires généralisés (GLM)

## glm() avec R

Dans `R`, on peut estimer un modèle linéaire généralisé avec la fonction `glm()`, qui ressemble beaucoup à la fonction `lm()`: 
.pull-left[

```r
glm(formula, 
    family = gaussian(link = "identity"), 
    data,
    ...)
```
]
.pull-right[

```r
lm(formula, 
    data,
    ...)
#
```

]

&lt;br&gt;

avec l'argument `family` (voir `?family`) qui prend le nom de la **fonction lien** (à l'intérieur de `link()`) et la **fonction de variance**.

Cette approche s'applique à d'autres distributions!

---

# Les modèles linéaires généralisés (GLM)

## Fonction de liens

| Distribution de `\(Y\)` | Nom du fonction lien | Fonction lien | Modèle | `R` |
|---------------------|--------------------|---------------|------------|-----|
| Normale | Identité | `\(g(\mu) = \mu\)`  | `\(\mu = \mathbf{X} \boldsymbol{\beta}\)` | `gaussian(link="identity")` | 
| Binomiale  | Logit  | `\(g(\mu) = \log\left(\dfrac{\mu}{1-\mu}\right)\)`  | `\(\log\left(\dfrac{\mu}{1-\mu}\right) = \mathbf{X} \boldsymbol{\beta}\)` | `binomial(link="logit")`| 
| Poisson   | Log | `\(g(\mu) = \log(\mu)\)` | `\(\log(\mu) = \mathbf{X} \boldsymbol{\beta}\)` | `poisson(link="log")`|
| Exponentielle | Inverse négative  | `\(g(\mu) = -\mu^{-1}\)`  | `\(-\mu^{-1} = \mathbf{X} \boldsymbol{\beta}\)` | `Gamma(link="inverse")` |

---

# GLM avec des données binaires

- Un GLM pour les données de présence / absence est également appelé une **régression logistique**.

- La fonction de lien **logit** est définie par:

`$$logit(p) = \log\frac{p}{1-p}$$`


```r
glm(formula, 
    family = binomial(link = "logit"), # aussi nommé "logistique"
    data,
    ...)
```

---

# GLM avec des données binaires (suite)

## Cas d'étude

&gt; On va ici s'intéresser à modéliser la probabilité de défaut de paiement d'un emprunteur. Un exemple de jeu de données "Default" disponible dans le package R (ISLR) contient des données sur le défaut de paiement de crédit pour 10000 clients.

## Import et inspection les données


```r
library(ISLR)
data &lt;- ISLR::Default
data &lt;- data[, c("default", "student")]
table(data$student, data$default)
#      
#         No  Yes
#   No  6850  206
#   Yes 2817  127
```

---

## Réalisation du test


```r
RES &lt;- glm(default ~ student, data = data, family = "binomial")
summary(RES)
# 
# Call:
# glm(formula = default ~ student, family = "binomial", data = data)
# 
# Deviance Residuals: 
#     Min       1Q   Median       3Q      Max  
# -0.2970  -0.2970  -0.2434  -0.2434   2.6585  
# 
# Coefficients:
#             Estimate Std. Error z value Pr(&gt;|z|)    
# (Intercept) -3.50413    0.07071  -49.55  &lt; 2e-16 ***
# studentYes   0.40489    0.11502    3.52 0.000431 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# (Dispersion parameter for binomial family taken to be 1)
# 
#     Null deviance: 2920.6  on 9999  degrees of freedom
# Residual deviance: 2908.7  on 9998  degrees of freedom
# AIC: 2912.7
# 
# Number of Fisher Scoring iterations: 6
```

---

## Conditions d'application

### Nombre de cas suffisants

- Pour réaliser une régression logistique, il est nécessaire d’avoir un nombre suffisant de données. En pratique, il est recommandé d’avoir au moins 10 fois plus d’événements que de paramètres dans le modèle.


```r
table(data$default)
# 
#   No  Yes 
# 9667  333
```

### Absence de surdispersion

`$$\widehat{\phi} = \frac{{deviance\; residuelle}} {nddl}$$`
`$$\widehat{\phi} = \frac{{2908.7}} {9998} = 0.29$$`

---

## Interprétation du modèle

&lt;u&gt;Equation du modèle:&lt;/u&gt; `\(\log\frac{p_{default}}{1 - p_{default}} = \beta_0 + \beta_1 \times student\)`

`\(\log\frac{p_{default}}{1 - p_{default}} = -3.5041 + 0.4049 \times student\)`

&lt;u&gt;Interprétation:&lt;/u&gt; Le coefficient pour "studentYes" indique l'effet de l'indicateur binaire "student" sur la probabilité de défaut de paiement. Dans ce cas, la variable "student" indique si l'emprunteur est un étudiant ou non. Nous pouvons voir que le coefficient est positif, ce qui suggère que les étudiants ont une probabilité de défaut de paiement plus élevée que les non-étudiants.

La fonction inverse de la transformation logit est donnée par:

&gt; p_default = exp(logit) / (1 + exp(logit))

Ainsi, si nous voulons calculer la probabilité de défaut de paiement pour un emprunteur qui est un étudiant, nous avons:

&gt; logit = -3.5041 + 0.4049 * 1 = -3.0992   
&gt; p_default = exp(-3.0992) / (1 + exp(-3.0992)) = 0.045

Cela signifie qu'un emprunteur qui est un étudiant a une probabilité de défaut de paiement d'environ 4,5%.

---

## Interprétation du modèle (suite)

De même, pour un emprunteur qui n'est pas un étudiant, nous avons:

&gt; logit = -3.5041 + 0.4049 * 0 = -3.5041   
&gt; p_default = exp(-3.5041) / (1 + exp(-3.5041)) = 0.029

Cela signifie qu'un emprunteur qui n'est pas un étudiant a une probabilité de défaut de paiement d'environ 2,9%.

---

## Prédiction du modèle


```r
newdata &lt;- data.frame(student = c("No", "Yes"))
pred &lt;- predict(RES, newdata, type = "link", se = TRUE)
pred
# $fit
#         1         2 
# -3.504128 -3.099241 
# 
# $se.fit
#          1          2 
# 0.07071301 0.09071385 
# 
# $residual.scale
# [1] 1
```

---

## Intervalles de confiance

`$$IC_{sup0.05} = \frac{e^{Coefficient+1.96*Erreur-type}}{1+e^{Coefficient+1.96*Erreur-type}}$$`

`$$IC_{inf0.05} = \frac{e^{Coefficient-1.96*Erreur-type}}{1+e^{Coefficient-1.96*Erreur-type}}$$`



```r
Prob1_SE_sup &lt;- exp(pred$fit[1]+1.96*pred$se.fit[1])/(1+exp(pred$fit[1]+1.96*pred$se.fit[1]))
Prob1_SE_inf &lt;- exp(pred$fit[1]-1.96*pred$se.fit[1])/(1+exp(pred$fit[1]-1.96*pred$se.fit[1]))
Prob2_SE_sup &lt;- exp(pred$fit[2]+1.96*pred$se.fit[2])/(1+exp(pred$fit[2]+1.96*pred$se.fit[2]))
Prob2_SE_inf &lt;- exp(pred$fit[2]-1.96*pred$se.fit[2])/(1+exp(pred$fit[2]-1.96*pred$se.fit[2]))
```

---
## Intervalles de confiance (suite)

### Représentation graphique


```r
GRAPH &lt;- barplot(c(0.029, 0.045), ylim = c(0,1), names.arg = c("Non-Etudiant", "Etudiant"))
segments(x0=GRAPH[1], y0=c(Prob1_SE_inf), x1 = GRAPH[1], y1 = c(Prob1_SE_sup))
segments(x0=GRAPH[2], y0=c(Prob2_SE_inf), x1 = GRAPH[2], y1 = c(Prob2_SE_sup))
```

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-98-1.png" width="432" style="display: block; margin: auto;" /&gt;

---
## Test de signification statistique


```r
anova(RES, test = "Chi")
# Analysis of Deviance Table
# 
# Model: binomial, link: logit
# 
# Response: default
# 
# Terms added sequentially (first to last)
# 
# 
#         Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
# NULL                     9999     2920.7              
# student  1   11.967      9998     2908.7 0.0005416 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

&lt;u&gt;Interprétation:&lt;/u&gt; La différence est significative. Le défaut de paiement est donc bien plus élevé chez les étudiants que les non-étudiants.

---

# Analyse de la déviance sur notre modèle


```r
# Modèle nul
null_model &lt;- glm(default ~ 1, data = data, family = "binomial")

# Modèle ajusté
fit &lt;- glm(default ~ student, data = data, family = "binomial")

# Analyse de la déviance
anova(null_model, fit, test = "Chisq")
# Analysis of Deviance Table
# 
# Model 1: default ~ 1
# Model 2: default ~ student
#   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
# 1      9999     2920.7                          
# 2      9998     2908.7  1   11.967 0.0005416 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```


---
# GLM avec des données de comptage

Les données de comptage sont caractérisées par:
  - des valeurs **positives**.
  - des valeurs **entières**.
  - une plus grande **variance** pour les grandes valeurs.

Généralement la distribution qui modèle le mieux ces données est la distribution de **Poisson**.

---
## Cas d'étude

&gt; Supposons que vous êtes responsable de la production de fruits dans une entreprise de vente de fruits. Vous voulez comprendre comment la température affecte la production de fruits et prédire la production en fonction de la température. Vous avez recueilli des données sur la température moyenne quotidienne (en degrés Celsius) et le nombre de fruits produits chaque jour pendant un mois. Vous voulez utiliser ces données pour créer un modèle GLM Poisson pour prédire le nombre de fruits produits en fonction de la température.

## Import et inspection les données


```r
fruit_data &lt;- read.csv("../data/fruit.csv")
str(fruit_data)
# 'data.frame':	31 obs. of  2 variables:
#  $ temperature: num  10.2 11.5 13.1 15.3 18.2 20.5 22.1 22.8 20.5 17.5 ...
#  $ nb_fruits  : int  12 9 13 15 18 22 26 28 24 20 ...
```

---

## Réalisation du test


```r
fruit_model &lt;- glm(nb_fruits ~ temperature, data = fruit_data, 
                   family = "poisson")
summary(fruit_model)
# 
# Call:
# glm(formula = nb_fruits ~ temperature, family = "poisson", data = fruit_data)
# 
# Deviance Residuals: 
#      Min        1Q    Median        3Q       Max  
# -0.91141  -0.21700  -0.05607   0.29628   0.67491  
# 
# Coefficients:
#             Estimate Std. Error z value Pr(&gt;|z|)    
# (Intercept) 1.677844   0.190384   8.813  &lt; 2e-16 ***
# temperature 0.070309   0.009489   7.409 1.27e-13 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# (Dispersion parameter for poisson family taken to be 1)
# 
#     Null deviance: 61.4604  on 30  degrees of freedom
# Residual deviance:  4.1903  on 29  degrees of freedom
# AIC: 157.18
# 
# Number of Fisher Scoring iterations: 4
```

---
## Conditions d'application
 
### Distribution des réponses selon une loi de Poisson

.pull-left[

```r
set.seed(1234) # permet de simuler toujours les mêmes comptages.
theoretic_count &lt;-rpois(31,mean(fruit_data$nb_fruits))

# on incorpore ces comptages théoriques dans un data frame
tc_df &lt;-data.frame(theoretic_count)

# on plot simultanémaent les comptages observés et les comptages théoriques
library(ggplot2)
ggplot(fruit_data,aes(nb_fruits))+
   geom_bar(fill="#1E90FF")+
   geom_bar(data=tc_df, aes(theoretic_count,fill="#1E90FF", alpha=0.5))+
   theme_classic()+
   theme(legend.position="none") 
```
]

.pull-right[
&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-104-1.png" width="432" style="display: block; margin: auto;" /&gt;
]

---
## Conditions d'application (suite)

### Evaluation de la surdispersion

`$$\widehat{\phi} = \frac{{deviance\; residuelle}} {nddl}$$`
`$$\widehat{\phi} = \frac{{4.1903}} {29} = 0.14$$`
&lt;img src="../images/dispParam.png" width="60%" style="display: block; margin: auto;" /&gt;

---

## Test de signification statistique

`\(log(\mu_{nbfruits}) = \beta_0 + \beta_1 \times temperature\)`

`\(log(\mu_{nbfruits}) = 1.67 + 0.07 \times temperature\)`


```r
anova(fruit_model, test="Chi")
# Analysis of Deviance Table
# 
# Model: poisson, link: log
# 
# Response: nb_fruits
# 
# Terms added sequentially (first to last)
# 
# 
#             Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
# NULL                           30      61.46              
# temperature  1    57.27        29       4.19 3.799e-14 ***
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

&lt;u&gt;Interprétation:&lt;/u&gt;Nous pouvons remarquer que la température influe significativement et positivement au seuil de 5%.

---

## Prédiction et représentation graphique

Supposons que nous voulons prédire le nombre de fruits produits pour une température de 25 degrés Celsius.


```r
newdata &lt;- data.frame(temperature = 25)
pred &lt;- predict(fruit_model, newdata, type = "link", se = TRUE)
pred
# $fit
#        1 
# 3.435556 
# 
# $se.fit
# [1] 0.06477099
# 
# $residual.scale
# [1] 1
```

---

## Prédiction et représentation graphique (suite)



```r
library(ggplot2)

# Prediction de la production de fruits pour chaque température
newdata &lt;- data.frame(temperature = seq(min(fruit_data$temperature), max(fruit_data$temperature), length.out = 100))
pred &lt;- predict(fruit_model, newdata = newdata, type = "response", se.fit = TRUE)

# Création du data frame avec les prédictions et intervalles de confiance
pred_df &lt;- data.frame(temp = newdata$temperature, pred = pred$fit, lower = pred$fit - qnorm(0.975) * pred$se.fit, upper = pred$fit + qnorm(0.975) * pred$se.fit)

# Création du graphique
ggplot() +
  geom_point(data = fruit_data, aes(x = temperature, y = nb_fruits)) +
  geom_line(data = pred_df, aes(x = temp, y = pred)) +
  geom_ribbon(data = pred_df, aes(x = temp, ymin = lower, ymax = upper), alpha = 0.2) +
  xlab("Température (°C)") +
  ylab("Nombre de fruits produits") +
  ggtitle("Production de fruits en fonction de la température") +
  theme_bw()

```

---

## Prédiction et représentation graphique (suite)


&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-108-1.png" width="432" style="display: block; margin: auto;" /&gt;


---

# GLM (suite)

&lt;img src="../images/defi.jpg" width="10%" style="display: block; margin: auto auto auto 0;" /&gt;

&lt;u&gt;Contexte:&lt;/u&gt;Vous êtes un biologiste qui étudie les facteurs qui influencent la survie des plantes. Vous avez mené une étude pour évaluer les effets de trois traitements (A, B et C) sur la survie de plantes sur une période de deux mois. Vous avez mesuré la survie de chaque plante toutes les deux semaines et vous avez également enregistré les variables suivantes pour chaque plante : la hauteur de la plante (en cm), le diamètre du tronc (en cm) et la quantité de lumière reçue chaque jour (en lux).

1. Importez le jeu de données "Plantes.csv" contenant les données de l'étude.
2. Visualisez les données pour comprendre la relation entre la survie des plantes et les différentes variables disponibles.
3. Formulez un modèle GLM pour évaluer les effets des traitements, de la hauteur, du diamètre et de la quantité de lumière sur la survie des plantes. Quelle distribution serait la plus appropriée pour ce modèle ? Justifiez votre choix.

---

# GLM (suite)

**Solution:**

1.


```r
plantes &lt;- read.csv("../../presentation/data/plantes.csv", header = TRUE)
head(plantes)
#   Plante Traitement Temps  Hauteur Diametre  Lumiere Survie
# 1      1          A     0 32.62457 1.879294 3901.510      1
# 2      2          A     0 33.11017 1.708230 4200.486      1
# 3      3          A     0 29.51657 1.929816 5079.874      1
# 4      4          A     0 29.62368 2.029342 4677.254      0
# 5      5          A     0 35.09579 2.324724 5146.417      0
# 6      6          A     0 33.55801 2.182242 7305.062      1
```

---

# GLM (suite)

2.


```r
# Chargez la bibliothèque ggplot2 pour les graphiques
library(ggplot2)

# Tracé d'un boxplot pour la relation entre la hauteur de la plante et la survie des plantes
p1 &lt;- ggplot(data = plantes, aes(x = as.factor(Survie), y = Hauteur)) +
  geom_boxplot() +
  labs(x = "Survie", y = "Hauteur de la plante (cm)") +
  ggtitle("Relation entre la hauteur de la plante et la survie")

# Tracé d'un boxplot pour la relation entre la quantité de lumière reçue et la survie des plantes
p2 &lt;- ggplot(data = plantes, aes(x = as.factor(Survie), y = Lumiere)) +
  geom_boxplot() +
  labs(x = "Survie", y = "Lumière reçue (lux)") +
  ggtitle("Relation entre la lumière reçue et la survie")

# Tracé d'un boxplot pour la relation entre le diamètre du tronc et la survie des plantes
p3 &lt;- ggplot(data = plantes, aes(x = as.factor(Survie), y = Diametre)) +
  geom_boxplot() +
  labs(y = "Diamètre du tronc (cm)", x = "Survie") +
  ggtitle("Relation entre le diamètre du tronc et la survie")

gridExtra::grid.arrange(p1, p2, p3, ncol = 3)

```

---

# GLM (suite)

2.

&lt;img src="Analyse_de_données_sous_R_files/figure-html/unnamed-chunk-111-1.png" width="1080" style="display: block; margin: auto;" /&gt;

---

# GLM (suite)

3.


```r
model1 &lt;- glm(Survie ~ Traitement + Hauteur + Diametre + Lumiere, data = plantes, 
    family = binomial)
summary(model1)
# 
# Call:
# glm(formula = Survie ~ Traitement + Hauteur + Diametre + Lumiere, 
#     family = binomial, data = plantes)
# 
# Deviance Residuals: 
#     Min       1Q   Median       3Q      Max  
# -2.0813   0.3344   0.5817   0.7127   1.4104  
# 
# Coefficients:
#               Estimate Std. Error z value Pr(&gt;|z|)  
# (Intercept)  1.7067026  3.1024998   0.550   0.5822  
# TraitementB  0.1127151  0.5601961   0.201   0.8405  
# TraitementC  0.3605765  0.5841883   0.617   0.5371  
# Hauteur      0.0959802  0.0473097   2.029   0.0425 *
# Diametre    -2.3038915  1.1431974  -2.015   0.0439 *
# Lumiere      0.0002386  0.0002261   1.055   0.2912  
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# 
# (Dispersion parameter for binomial family taken to be 1)
# 
#     Null deviance: 127.96  on 119  degrees of freedom
# Residual deviance: 117.26  on 114  degrees of freedom
# AIC: 129.26
# 
# Number of Fisher Scoring iterations: 4
```

---

# GLM (suite)

3.


```r
anova(model1, test = "Chi")
# Analysis of Deviance Table
# 
# Model: binomial, link: logit
# 
# Response: Survie
# 
# Terms added sequentially (first to last)
# 
# 
#            Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)  
# NULL                         119     127.96           
# Traitement  2   0.2872       117     127.67  0.86623  
# Hauteur     1   5.2699       116     122.40  0.02170 *
# Diametre    1   4.0005       115     118.40  0.04549 *
# Lumiere     1   1.1404       114     117.26  0.28556  
# ---
# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---

# Test du `\(\chi^2\)` d'indépendance

## Cas d'étude

&gt; Nous souhaitons savoir si la répartition du dauphin bleu et blanc, du rorqual et de la baleine à bosse par rapport à la profondeur de la zone sont les mêmes. Pour répondre à cette question des observateurs partent patrouiller différentes zones, comptent les individus rencontrés en surface et notent la profondeurau lieu d'observation.   

## Utilisation

Tester l'indépendance entre variables catégorielles.

---

## Conditions d'utilisation

- Les observations sont indépendantes.

- Les effectifs doivent-être importants.

## Fonction R

&gt; chisq.test{stats}   

- si les données sont présentées sous forme de tableau:

&gt; chisq.test(colonne1, colonne2)

- si les données sont sous forme de table de contingence:

&gt; chisq.test(table_de_contingence)

---

## Résolution du cas d'étude

### Création de la table de contingence


```r
Data &lt;- as.table(rbind(c(117, 104, 149), c(17, 29, 86), c(22, 15, 8)))
dimnames(Data) &lt;- list(Mammifere = c("Dauphin", "Rorqual", "Baleine_A_Bosse"),
                       Bathymetrie = c("PeuProfond", "Moyen", "Profond"))
Data
#                  Bathymetrie
# Mammifere         PeuProfond Moyen Profond
#   Dauphin                117   104     149
#   Rorqual                 17    29      86
#   Baleine_A_Bosse         22    15       8
```

---

### Test du `\(\chi^2\)`


```r
Xsq &lt;- chisq.test(Data)
Xsq
# 
# 	Pearson's Chi-squared test
# 
# data:  Data
# X-squared = 42.582, df = 4, p-value = 1.263e-08
```

&lt;u&gt;Interprétation:&lt;/u&gt;L'analyse de la table de contingence montre un lien significatif entre l'espèce et la localisation sur zone bathymétrique (p=1.26e-08; `\(\chi^2\)` = 42.582; dll = 4).

---

# Test de Fisher

## Cas d'étude

&gt; Nous souhaitons savoir si il existe un lien entre la couleur des yeux et celle des cheveux ? Les résultts présentés sont ceux d'une enquête menée sur 161 étudiants.

## Utilisation

Tester l'indépendance entre variables catégorielles.

---

## Conditions d'utilisation

- Les observations sont indépendantes.

- Les effectifs peuvent être faibles.

## Fonction R

&gt; fisher.test{stats}   

- si les données sont présentées sous forme de tableau:

&gt; fisher.test(colonne1, colonne2)

- si les données sont sous forme de table de contingence:

&gt; fisher.test(table_de_contingence)

---

## Résolution du cas d'étude

### Création de la table de contingence


```r
amphi &lt;- as.table(rbind(c(13, 11, 0, 0), c(2, 2, 0, 1), c(3, 60, 26, 1),
                        c(0, 1, 10, 1), c(1, 20, 7, 1)))
dimnames(amphi) &lt;- list(Yeux = c("Bleu", "Gris", "Marron",
                                 "Noir", "Vert"),
                       Cheveux = c("Blond", "Châtain", "Noir", "Roux"))
amphi
#         Cheveux
# Yeux     Blond Châtain Noir Roux
#   Bleu      13      11    0    0
#   Gris       2       2    0    1
#   Marron     3      60   26    1
#   Noir       0       1   10    1
#   Vert       1      20    7    1
```

---

### Test de Fisher


```r
fisher.test(amphi, workspace = 20000000)
# 
# 	Fisher's Exact Test for Count Data
# 
# data:  amphi
# p-value = 2.506e-12
# alternative hypothesis: two.sided
```

&lt;u&gt;Interprétation:&lt;/u&gt;L'analyse de la table de contingence montre un lien significatif entre la couleur des yeux et celle des cheveux (p=2.5e-12; CPE de Fisher).

---


# Comparer plusieurs proportions

## Cas d'étude

&gt; Nous reprenons l'exemple précédent pour nous intéresser à la répartition des dauphins en fonction de la zone bathymétrique, par rapport aux autres espèces de mammifères rencontrées.

## Utilisation

Tester l'hypothèse qu'au moins une proportion diffère des autres.

---

## Conditions d'utilisation

- Les observations sont indépendantes.

- Nous mesurons une proportion d'événements considérés comme étant des "succès".

## Fonction R

&gt; prop.test{stats}   

- Hypothèse bilatérale:

&gt; prop.test(vecteur_succes_observes, vecteur_evenements_enregistres)   
&gt; prop.test(matrice)

- Hypothèse unilatérale:

&gt; prop.test(matrice, alternative="greater")

---

## Résolution du cas d'étude

### Création de la matrice


```r
matri &lt;- c(117, 104, 149, 39, 44, 94)
dim(matri) &lt;- c(3, 2)
matri
#      [,1] [,2]
# [1,]  117   39
# [2,]  104   44
# [3,]  149   94
```

### Test de comparaison de proportions


```r
prop.test(matri)
# 
# 	3-sample test for equality of proportions without continuity correction
# 
# data:  matri
# X-squared = 8.7675, df = 2, p-value = 0.01248
# alternative hypothesis: two.sided
# sample estimates:
#    prop 1    prop 2    prop 3 
# 0.7500000 0.7027027 0.6131687
```

&lt;u&gt;Interprétation:&lt;/u&gt;Le test de comparaison de proportion est significatif, ce qui indique qu'au risque d'erreur alpha de 5%, au moins une des proportions diffère des autres(p=0.012; `\(\chi^2\)` = 8.77; dll = 2).

---

## Test de proportions

&lt;img src="../images/defi.jpg" width="10%" style="display: block; margin: auto auto auto 0;" /&gt;

A partir de l'exemple du cas d'étude précédent:

1. Nous souhaitons savoir si la proportion de dauphins par rapport aux autres espèces observées est différente entre les zones peu profonde et moyennement profonde.

2. Connaissons le régime alimentaire des dauphins et l'abondance des proies dans les différentes zones, nous formulons l'hypothèse que la proportion de dauphins par rapport aux autres mammifères doit être supérieure dans la zone peu profonde par rapport à la zone profonde.

---

## Test de proportions (suite)

**Solution**

1.


```r
matri &lt;- c(117, 104, 39, 44)
dim(matri) = c(2,2)
matri
#      [,1] [,2]
# [1,]  117   39
# [2,]  104   44

prop.test(matri)
# 
# 	2-sample test for equality of proportions with continuity correction
# 
# data:  matri
# X-squared = 0.63427, df = 1, p-value = 0.4258
# alternative hypothesis: two.sided
# 95 percent confidence interval:
#  -0.05948405  0.15407864
# sample estimates:
#    prop 1    prop 2 
# 0.7500000 0.7027027
```

---

## Test de proportions (suite)

1.

&lt;u&gt;interprétation:&lt;/u&gt;Le test de proportions avec correction de continuité ne permet pas de montrer une différence significative entre la proportion de dauphins en zone peu profonde et celle en zone moyennement profonde (p= 0.43; `\(\chi^2 = 0.63; ddl = 1\)`).

---

## Test de proportions (suite)

2.


```r
prop.test(c(117,149), c((117+39),(149+94)), alternative = "greater")
# 
# 	2-sample test for equality of proportions with continuity correction
# 
# data:  c(117, 149) out of c((117 + 39), (149 + 94))
# X-squared = 7.4007, df = 1, p-value = 0.00326
# alternative hypothesis: greater
# 95 percent confidence interval:
#  0.05480434 1.00000000
# sample estimates:
#    prop 1    prop 2 
# 0.7500000 0.6131687
```

&lt;u&gt;interprétation:&lt;/u&gt;Conformément à l'hypothèse, en zone peu profonde la proprtion de dauphins (75%) est supérieure à celle observée en zone profonde (61.3%). De plus cette différence est significative (p=3.26.10^-3; `\(\chi^2\)` = 23.07; ddl = 1; test unilatéral de cmparaison de proprtion avec correction de continuité)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
